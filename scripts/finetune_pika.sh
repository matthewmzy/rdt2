#!/bin/bash
# ============================================================
# RDT2 LoRA 微调脚本 - Pika 鱼眼相机数据集
# ============================================================
# 
# 用法:
#   1. 先转换数据集（如果尚未转换）:
#      bash scripts/finetune_pika_fisheye.sh --convert-only
#   
#   2. 只训练（假设数据已转换）:
#      bash scripts/finetune_pika_fisheye.sh --train-only
#   
#   3. 完整流程（转换 + 训练）:
#      bash scripts/finetune_pika_fisheye.sh
#
# 数据集说明:
#   - 使用鱼眼相机 (FisheyeCamera) 作为 RGB 输入
#   - 图像拼接顺序: [左, 右] (与官方一致)
#   - 动作类型: 相对位姿 (Relative Pose)
#   - 动作维度: 20 = 右臂(10) + 左臂(10)
#   - 每臂: [相对位移(3) + rotation_6d(6) + gripper_width(1)]
#
# ============================================================

set -e  # 遇到错误立即退出

# ===================== 配置区域 =====================

# 任务名称
TASK="pika-bottle-fisheye"

# 任务指令 (遵循 "Verb Object." 格式)
INSTRUCTION="Put the bottle into the tape ring, and then take it out with the other hand."

# 数据路径
RAW_DATA_DIR="pika_raw_data"                           # 原始 Pika 数据目录
OUTPUT_SHARD_DIR="rdt2_pika_shards"              # 修复后的 WebDataset 目录
DATASET_CONFIG_PATH="rdt2_pika_shards/dataset_config.yaml"

# 模型配置
TOKENIZER_ID="Qwen/Qwen2.5-VL-7B-Instruct"
VAE_ID="robotics-diffusion-transformer/RVQActionTokenizer"
MODEL_ID="robotics-diffusion-transformer/RDT2-VQ"
OUTPUT_DIR="./outputs/vqvla-sft-${TASK}-fixed-lora"

# 训练超参数
# 注意: 单卡 48GB 显存，batch_size 需要设置较小 (4-8)
# 可以通过 gradient_accumulation 来模拟更大的有效 batch size
TRAIN_BATCH_SIZE=4
GRADIENT_ACCUMULATION_STEPS=8  # 有效 batch size = 4 * 8 = 32
EVAL_BATCH_SIZE=4
MAX_TRAIN_STEPS=5000
LEARNING_RATE=1e-4
LR_WARMUP_STEPS=200
LOGGING_STEPS=25
CHECKPOINTING_STEP=500
CHECKPOINTS_TOTAL_LIMIT=10
DATALOADER_NUM_WORKERS=8
SAMPLES_PER_SHARD=1000

# HuggingFace 镜像 (国内加速)
export HF_ENDPOINT=https://hf-mirror.com

# 确保使用conda环境的库 (解决libtiff/libjpeg兼容性问题)
export LD_LIBRARY_PATH="$CONDA_PREFIX/lib:$LD_LIBRARY_PATH"
export LD_PRELOAD="$CONDA_PREFIX/lib/libjpeg.so.8"

# 设置分布式训练环境变量 (单机单卡时必须设置，避免 mpi4py 依赖)
export MASTER_ADDR=localhost
export MASTER_PORT=29500
export WORLD_SIZE=1
export RANK=0
export LOCAL_RANK=0

# CUDA 显存优化 (避免碎片化)
export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True

# ===================== 辅助函数 =====================

print_header() {
    echo ""
    echo "============================================================"
    echo "$1"
    echo "============================================================"
}

check_conda() {
    if ! command -v conda &> /dev/null; then
        echo "Error: conda not found. Please install Anaconda/Miniconda."
        exit 1
    fi
}

activate_conda() {
    # 激活 conda 环境
    source ~/anaconda3/etc/profile.d/conda.sh
    conda activate rdt2
    echo "Activated conda environment: rdt2"
    echo "Python: $(which python)"
    echo "Python version: $(python --version)"
}

# ===================== 数据转换 =====================

convert_dataset() {
    print_header "转换数据集为 WebDataset 格式"
    
    python pika_test_scripts/convert_pika_to_rdt2.py \
        --input-dir "$RAW_DATA_DIR" \
        --output-dir "$OUTPUT_SHARD_DIR" \
        --instruction "$INSTRUCTION" \
        --normalizer-path "normalizer.pt" \
        --samples-per-shard "$SAMPLES_PER_SHARD"
    
    print_header "数据集转换完成!"
    echo "输出目录: $OUTPUT_SHARD_DIR"
    echo "Shards 数量: $(ls -1 ${OUTPUT_SHARD_DIR}/shard-*.tar 2>/dev/null | wc -l)"
}

# ===================== 创建数据集配置 =====================

create_dataset_config() {
    print_header "创建数据集配置文件"
    
    cat > "$DATASET_CONFIG_PATH" << EOF
# RDT2 dataset config for Pika fisheye camera data
# Auto-generated by finetune_pika.sh
name: pika/bottle_task
type: single
shards_dir: $(realpath "$OUTPUT_SHARD_DIR")
kwargs:
  instruction_path: $(realpath "$OUTPUT_SHARD_DIR")/instruction.json
  normalizer_path: $(realpath "normalizer.pt")
EOF
    
    echo "配置文件已保存: $DATASET_CONFIG_PATH"
}

# ===================== 训练 =====================

train_model() {
    print_header "开始 LoRA 微调训练"
    
    echo "任务名称: $TASK"
    echo "模型: $MODEL_ID"
    echo "数据集配置: $DATASET_CONFIG_PATH"
    echo "输出目录: $OUTPUT_DIR"
    echo "Batch Size: $TRAIN_BATCH_SIZE"
    echo "Max Steps: $MAX_TRAIN_STEPS"
    echo "Learning Rate: $LEARNING_RATE"
    echo ""
    
    mkdir -p "$OUTPUT_DIR"
    
    accelerate launch main.py \
        --deepspeed="scripts/zero1.json" \
        --tokenizer_name="$TOKENIZER_ID" \
        --vae_name="$VAE_ID" \
        --pretrained_model_name_or_path="$MODEL_ID" \
        --output_dir="$OUTPUT_DIR" \
        --train_batch_size="$TRAIN_BATCH_SIZE" \
        --eval_batch_size="$EVAL_BATCH_SIZE" \
        --gradient_accumulation_steps="$GRADIENT_ACCUMULATION_STEPS" \
        --max_train_steps="$MAX_TRAIN_STEPS" \
        --eval_strategy="no" \
        --logging_steps="$LOGGING_STEPS" \
        --checkpoints_total_limit="$CHECKPOINTS_TOTAL_LIMIT" \
        --checkpointing_step="$CHECKPOINTING_STEP" \
        --lr_scheduler="cosine" \
        --learning_rate="$LEARNING_RATE" \
        --mixed_precision="bf16" \
        --dataloader_num_workers="$DATALOADER_NUM_WORKERS" \
        --gradient_checkpointing \
        --log_level="info" \
        --report_to="wandb" \
        --lr_warmup_steps="$LR_WARMUP_STEPS" \
        --dataset="$DATASET_CONFIG_PATH" \
        --image_corruption \
        --use_lora \
        --use_default_collate_fn_for_eval
    
    print_header "训练完成!"
    echo "模型检查点保存在: $OUTPUT_DIR"
}

# ===================== 主流程 =====================

main() {
    cd "$(dirname "$0")/.."  # 切换到项目根目录
    
    check_conda
    activate_conda
    
    case "${1:-}" in
        --convert-only)
            print_header "仅转换数据集模式"
            convert_dataset
            create_dataset_config
            ;;
        --train-only)
            print_header "仅训练模式"
            if [ ! -d "$OUTPUT_SHARD_DIR" ]; then
                echo "Error: 数据集目录不存在: $OUTPUT_SHARD_DIR"
                echo "请先运行: bash scripts/finetune_pika_fisheye.sh --convert-only"
                exit 1
            fi
            create_dataset_config
            train_model
            ;;
        *)
            print_header "完整流程: 数据转换 + 训练"
            convert_dataset
            create_dataset_config
            train_model
            ;;
    esac
}

main "$@"
